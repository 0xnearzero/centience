{"url":"https://replicate.com/fofr/live-portrait","content":{"title":"fofr/live-portrait – Run with an API on Replicate","description":"A portrait animation model that uses a driving video source, allowing for control over face scaling, lip and eye retargeting, and stitching.","bodyContent":"Explore\nPlayground Beta\nPricing\nDocs\nBlog\nChangelog\nSign in\nGet started\nfofr / live-portrait \n\nPortrait animation using a driving video source\n\nCold\nPublic\n57.2K runs\nA40 (Large)\nGitHub\nPaper\nLicense\nRun with an API\nPlayground\nAPI\nExamples\nREADME\nVersions\nInput\nForm\nJSON\nNode.js\nPython\nHTTP\nCog\nDocker\nface_image\n*\nfile\nUpload a file from your machine\nTake a photo with your webcam\nPREVIEW\nClear file\n\nAn image with a face\n\ndriving_video\n*\nfile\nUpload a file from your machine\n\nA video to drive the animation\n\nvideo_frame_load_cap\ninteger\n\nThe maximum number of frames to load from the driving video. Set to 0 to use all frames.\n\nDefault: 128\n\nvideo_select_every_n_frames\ninteger\n\nSelect every nth frame from the driving video. Set to 1 to use all frames.\n\nDefault: 1\n\nlive_portrait_dsize\ninteger\n(minimum: 64, maximum: 2048)\nlive_portrait_dsize\n\nSize of the output image\n\nDefault: 512\n\nlive_portrait_scale\nnumber\n(minimum: 1, maximum: 4)\nlive_portrait_scale\n\nScaling factor for the face\n\nDefault: 2.3\n\nlive_portrait_vx_ratio\nnumber\n(minimum: -1, maximum: 1)\nlive_portrait_vx_ratio\n\nHorizontal shift ratio\n\nDefault: 0\n\nlive_portrait_vy_ratio\nnumber\n(minimum: -1, maximum: 1)\nlive_portrait_vy_ratio\n\nVertical shift ratio\n\nDefault: -0.12\n\nlive_portrait_lip_zero\nboolean\n\nEnable lip zero\n\nDefault: true\n\nlive_portrait_eye_retargeting\nboolean\n\nEnable eye retargeting\n\nDefault: false\n\nlive_portrait_eyes_retargeting_multiplier\nnumber\n(minimum: 0.01, maximum: 10)\nlive_portrait_eyes_retargeting_multiplier\n\nMultiplier for eye retargeting\n\nDefault: 1\n\nlive_portrait_lip_retargeting\nboolean\n\nEnable lip retargeting\n\nDefault: false\n\nlive_portrait_lip_retargeting_multiplier\nnumber\n(minimum: 0.01, maximum: 10)\nlive_portrait_lip_retargeting_multiplier\n\nMultiplier for lip retargeting\n\nDefault: 1\n\nlive_portrait_stitching\nboolean\n\nEnable stitching\n\nDefault: true\n\nlive_portrait_relative\nboolean\n\nUse relative positioning\n\nDefault: true\n\nAdd a payment method to run this model.\n\nEach run costs approximately $0.032. Alternatively, try out our featured models for free.\n\nSign in with GitHub\n\nBy signing in, you agree to our\nterms of service and privacy policy\n\nOutput\nPreview\nJSON\nGenerated in\n24.4 seconds\nTweak it\nDownload\nReport\nShow logs\nExamples\n\nView more examples \n\n \n \n \nRun time and cost\n\nThis model costs approximately $0.032 to run on Replicate, or 31 runs per $1, but this varies depending on your inputs. It is also open source and you can run it on your own computer with Docker.\n\nThis model runs on Nvidia A40 (Large) GPU hardware. Predictions typically complete within 44 seconds. The predict time for this model varies significantly based on the inputs.\n\nReadme\n\nEfficient Portrait Animation with Stitching and Retargeting Control\n\nPaper: https://arxiv.org/pdf/2407.03168\nWebsite: https://liveportrait.github.io/\nExample driving videos\n\nTry these videos:\n\nhttps://github.com/KwaiVGI/LivePortrait/tree/main/assets/examples/driving\n\nLicense\n\nLivePortrait uses InsightFace buffalo_l models, meaning this model cannot be used commercially. The LivePortrait code and weights are released under an MIT license.\n\nImplementation\n\nThis model uses the ComfyUI custom node created by Kijai:\n\nhttps://github.com/kijai/ComfyUI-LivePortraitKJ\n\nAnd the safetensor weights they converted:\n\nhttps://huggingface.co/Kijai/LivePortrait_safetensors/tree/main\n\nReplicate\nHome\nAbout\nJoin us\nTerms\nPrivacy\nStatus\nSupport"}}